# -*- coding: utf-8 -*-
"""Rainfall prediction .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uKvGcqdnZA3qbdytBH5ToIzeBvoGO5SI
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sb
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import metrics
import warnings
warnings.filterwarnings('ignore')

from google.colab import files
uploaded = files.upload()
df = pd.read_csv('Rainfall.csv')
df.head()

df.shape

df.info()

df.describe().T

df.isnull().sum()

df.columns

df.rename(str.strip,
          axis='columns',
          inplace=True)

df.columns

for col in df.columns:

  # Checking if the column contains
  # any null values
  if df[col].isnull().sum() > 0:
    val = df[col].mean()
    df[col] = df[col].fillna(val)

df.isnull().sum().sum()

import matplotlib.pyplot as plt

# Assuming df is your dataframe and 'rainfall' is the target column
rainfall_counts = df['rainfall'].value_counts()

# Creating a bar chart
plt.bar(rainfall_counts.index, rainfall_counts.values)
plt.xlabel('Rainfall')
plt.ylabel('Count')
plt.title('Rainfall Distribution')
plt.show()

X = df.drop('rainfall',axis=1)
# Putting response variable to y
y = df['rainfall']

# Splitting the data into train and test
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)

# Check the shape of X_train and X_test
print("\nShape of X_train is:",X_train.shape,"\n Shape of X_test is:", X_test.shape)

# Check the shape of y_train and y_test
print("\nShape of y_train is:",y_train.shape,"\n Shape of y_test is:", y_test.shape)



import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn import metrics
df.groupby('rainfall').mean()

features = list(df.select_dtypes(include = np.number).columns)
features.remove('day')
print(features)

plt.subplots(figsize=(15,8))

for i, col in enumerate(features):
  plt.subplot(3,4, i + 1)
  sb.distplot(df[col])
plt.tight_layout()
plt.show()

plt.subplots(figsize=(15,8))

for i, col in enumerate(features):
  plt.subplot(3,4, i + 1)
  sb.boxplot(df[col])
plt.tight_layout()
plt.show()

df.replace({'yes':1, 'no':0}, inplace=True)

plt.figure(figsize=(10,10))
sb.heatmap(df.corr() > 0.8,
           annot=True,
           cbar=False)
plt.show()

#Logistic Regression

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Load the rainfall dataset
df = pd.read_csv('Rainfall.csv')  # Update with the actual path to your dataset
X = df.drop('rainfall', axis=1)  # Update 'rainfall' with the actual target column name
y = df['rainfall']

# Convert the target variable to binary (1 for rain, 0 for no rain) if necessary
# y = (y > threshold).astype(int)  # Uncomment and modify if binary classification is needed

# Split the data into training, validation, and testing sets
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Drop rows with missing values
X_train.dropna(inplace=True)
y_train = y_train[X_train.index]  # Align y_train with dropped rows
X_val.dropna(inplace=True)
y_val = y_val[X_val.index]  # Align y_val with dropped rows
X_test.dropna(inplace=True)
y_test = y_test[X_test.index]  # Align y_test with dropped rows


# Standardize features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)
X_test = scaler.transform(X_test)

# Train the Logistic Regression model
model = LogisticRegression()
model.fit(X_train, y_train)

# Make predictions on the validation and test sets
y_val_pred = model.predict(X_val)
y_test_pred = model.predict(X_test)

# Evaluate the model
train_accuracy = model.score(X_train, y_train)
val_accuracy = model.score(X_val, y_val)
test_accuracy = model.score(X_test, y_test)
accuracy = accuracy_score(y_test, y_test_pred)
classification_rep = classification_report(y_test, y_test_pred)

print("Training Accuracy: {:.2f}%".format(train_accuracy * 100))
print("Validation Accuracy: {:.2f}%".format(val_accuracy * 100))
print("Testing Accuracy: {:.2f}%".format(test_accuracy * 100))
print("Accuracy: {:.2f}%".format(accuracy * 100))
print("Classification Report:\n", classification_rep)
print("Confusion Matrix:\n", confusion_matrix(y_test, y_test_pred))
ConfusionMatrixDisplay.from_predictions(y_test, y_test_pred)
plt.show()

#AdaBoost

import pandas as pd
import numpy as np
from sklearn.ensemble import AdaBoostClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay
from sklearn.impute import SimpleImputer # Import SimpleImputer for handling missing values
import matplotlib.pyplot as plt

# Load the rainfall dataset
df = pd.read_csv('Rainfall.csv')  # Update with the actual path to your dataset
X = df.drop('rainfall', axis=1)  # Update 'rainfall' with the actual target column name
y = df['rainfall']

# Split the data into training, validation, and testing sets
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Impute missing values using the mean
imputer = SimpleImputer(strategy='mean') # Create an imputer instance
X_train = imputer.fit_transform(X_train) # Fit and transform on training data
X_val = imputer.transform(X_val) # Transform validation data
X_test = imputer.transform(X_test) # Transform test data


# Create and train the AdaBoost classifier
abc = AdaBoostClassifier(n_estimators=50, learning_rate=1)
abc.fit(X_train, y_train)

# Make predictions on the validation and test sets
y_val_pred = abc.predict(X_val)
y_test_pred = abc.predict(X_test)

# Evaluate the model
train_accuracy = abc.score(X_train, y_train)
val_accuracy = abc.score(X_val, y_val)
test_accuracy = abc.score(X_test, y_test)
accuracy = accuracy_score(y_test, y_test_pred)
classification_rep = classification_report(y_test, y_test_pred)

print("Training Accuracy: {:.2f}%".format(train_accuracy * 100))
print("Validation Accuracy: {:.2f}%".format(val_accuracy * 100))
print("Testing Accuracy: {:.2f}%".format(test_accuracy * 100))
print("Accuracy: {:.2f}%".format(accuracy * 100))
print("Classification Report:\n", classification_rep)
print("Confusion Matrix:\n", confusion_matrix(y_test, y_test_pred))
ConfusionMatrixDisplay.from_predictions(y_test, y_test_pred)
plt.show()

#Random Forest

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay

# Load the rainfall dataset
df = pd.read_csv('Rainfall.csv')  # Update with the actual path to your dataset
X = df.drop('rainfall', axis=1)  # Update 'rainfall' with the actual target column name
y = df['rainfall']

# Split the data into training, validation, and testing sets
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Train the Random Forest model
classifier_rf = RandomForestClassifier(random_state=42, n_jobs=-1, max_depth=5, n_estimators=100, oob_score=True)
classifier_rf.fit(X_train, y_train)

# Make predictions on the validation and test sets
y_val_pred = classifier_rf.predict(X_val)
y_test_pred = classifier_rf.predict(X_test)

# Evaluate the model
train_accuracy = classifier_rf.score(X_train, y_train)
val_accuracy = classifier_rf.score(X_val, y_val)
test_accuracy = classifier_rf.score(X_test, y_test)
accuracy = accuracy_score(y_test, y_test_pred)
classification_rep = classification_report(y_test, y_test_pred)

print("Training Accuracy: {:.2f}%".format(train_accuracy * 100))
print("Validation Accuracy: {:.2f}%".format(val_accuracy * 100))
print("Testing Accuracy: {:.2f}%".format(test_accuracy * 100))
print("Accuracy: {:.2f}%".format(accuracy * 100))
print("Classification Report:\n", classification_rep)
print("Confusion Matrix:\n", confusion_matrix(y_test, y_test_pred))
ConfusionMatrixDisplay.from_predictions(y_test, y_test_pred)
plt.show()